{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvucgFmR8lAM"
      },
      "source": [
        "# Assignment #3: A simple language classifier with scikit-learn and Keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jjHvbmX82p5",
        "outputId": "ec2a214d-3d86-4b73-9fba-68126e41f8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-hI6mHg8lAY"
      },
      "source": [
        "Author: Pierre Nugues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf8FW--U8lAZ"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHFidkkz8lAa"
      },
      "source": [
        "In this assignment, you will implement a language detector inspired from Google's _Compact language detector_, version 3 (CLD3): https://github.com/google/cld3. CLD3 is written in C++ and its code is available from GitHub. The objectives of the assignment are to:\n",
        "* Write a program to classify languages\n",
        "* Use neural networks with sklearn and either Keras or PyTorch\n",
        "* Know what a classifier is\n",
        "* Write a short report of 1 to 2 pages to describe your program. You will notably comment the performance you obtained and how you could improve it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVz2zsjH8lAb"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJQLTnXN8lAc"
      },
      "source": [
        "### System Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktfpxSyP8lAd"
      },
      "source": [
        "Read the GitHub description of CLD3, https://github.com/google/cld3, (_Model_ section). In your individual report you will:\n",
        "1. Summarize the system in two or three sentences;\n",
        "2. Outline the CLD3 overall architecture in a figure. Use building blocks only and do not specify the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7gzqwmv8lAd"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IP4mx4h8lAe"
      },
      "outputs": [],
      "source": [
        "import bz2\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import requests\n",
        "import sys\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onGwKRO58lAh"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG89E4M48lAi"
      },
      "source": [
        "As dataset, we will use Tatoeba, https://tatoeba.org/eng/downloads. It consists of more than 8 million short texts in 347 languages and it is available in one file called `sentences.csv`.\n",
        "\n",
        "The dataset is structured this way: There is one text per line, where each line consists of the three following fields separated by tabulations and ended by a carriage return:\n",
        "```\n",
        "sentence id [tab] language code [tab] text [cr]\n",
        "```\n",
        "Each text (sentence) has a unique id and has a language code that follows the ISO 639-3 standard (see below). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XprB19038lAj"
      },
      "source": [
        "### Scope of the lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWEoZ-58lAj"
      },
      "source": [
        "In this lab, you will consider three languages only: French (fra), English (eng), and Swedish (swe). Below is an excerpt of the Tatoeba dataset limited to these three languages: \n",
        "\n",
        "```\n",
        "1276    eng     Let's try something.\n",
        "1277    eng     I have to go to sleep.\n",
        "1280    eng     Today is June 18th and it is Muiriel's birthday!\n",
        "...\n",
        "1115    fra     Lorsqu'il a demandé qui avait cassé la fenêtre, tous les garçons ont pris un air innocent.\n",
        "1279    fra     Je ne supporte pas ce type.\n",
        "1441    fra     Pour une fois dans ma vie je fais un bon geste... Et ça ne sert à rien.\n",
        "...\n",
        "337413  swe     Vi trodde att det var ett flygande tefat.\n",
        "341910  swe     Detta är huset jag bodde i när jag var barn.\n",
        "341938  swe     Vi hade roligt på stranden igår.\n",
        "...\n",
        "```\n",
        "Tatoeba is updated continuously. The examples from this dataset come from a corpus your instructor downloaded on September 23, 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlVqe8pp8lAl"
      },
      "source": [
        "### Understanding the $\\mathbf{X}$ matrix (feature matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnH0-2dJ8lAl"
      },
      "source": [
        "You will now investigate the CLD3 features:\n",
        " *  What are the features CLD3 extracts from each text?\n",
        " * Create manually a simplified $\\mathbf{X}$ matrix where you will represent the 9 texts with CLD3 features. You will use a restricted set of features: You will only consider the letters _a_, _b_, and _n_ and the bigrams _an_, _ba_, and _na_. You will ignore the the rest of letters and bigrams as well as the trigrams. Your matrix will have 9 rows and 6 columns, each column will contain these counts: `[#a, #b, #n, #an, #ba, #na]`.\n",
        "\n",
        "The CLD3's original description uses relative frequencies (counts of a letter divided by the total counts of letters in the text). Here, you will use the raw counts. To help you, your instructor filled the fourth row of the matrix corresponding to the first text in French. Fill in the rest. You will include this matrix in your report. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvVVvdjw8lAm"
      },
      "source": [
        "$\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "0& 0& 1& 0&0& 0\\\\\n",
        "0& 0& 0& 0&0& 0\\\\\n",
        "3& 1& 2& 1&0& 0\\\\\n",
        "8& 0& 8& 1&0&0\\\\\n",
        "1& 0& 1& 0&0& 0\\\\\n",
        "3& 1& 5& 1&0& 0\\\\\n",
        "3& 0& 1& 0&0& 0\\\\\n",
        "4& 2& 2& 0&0& 0\\\\\n",
        "2& 0& 1& 1&0& 0\\\\\n",
        "\\end{bmatrix}$\n",
        "; $\\mathbf{y} =\n",
        "\\begin{bmatrix}\n",
        "     \\text{eng} \\\\\n",
        "     \\text{eng}\\\\\n",
        "     \\text{eng}\\\\\n",
        "    \\text{fra}\\\\\n",
        "   \\text{fra}  \\\\\n",
        "     \\text{fra}\\\\\n",
        "    \\text{swe}\\\\\n",
        " \\text{swe}   \\\\\n",
        " \\text{swe}   \n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYgFb4LO8lAn"
      },
      "source": [
        "## Programming: Extracting the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAeis0DR8lAn"
      },
      "source": [
        "Before you start programming, download the Tatoeba dataset. You can use the intructions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHapuQXB8lAn"
      },
      "outputs": [],
      "source": [
        "!wget https://downloads.tatoeba.org/exports/sentences.tar.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZOsJvsw8lAo"
      },
      "outputs": [],
      "source": [
        "!tar -xvjf sentences.tar.bz2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1Poc09Y8lAo"
      },
      "source": [
        "### Loading and filtering the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTqEvLSn8lAp"
      },
      "source": [
        "Run the code to read the dataset and split it into lines. You may have to change the path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6-q7WYG8lAp",
        "outputId": "eaa8fce0-7da3-4441-f61f-55edb0a68f61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1\\tcmn\\t我們試試看！',\n",
              " '2\\tcmn\\t我该去睡觉了。',\n",
              " '3\\tcmn\\t你在干什麼啊？',\n",
              " '4\\tcmn\\t這是什麼啊？',\n",
              " '5\\tcmn\\t今天是６月１８号，也是Muiriel的生日！',\n",
              " '6\\tcmn\\t生日快乐，Muiriel！',\n",
              " '7\\tcmn\\tMuiriel现在20岁了。',\n",
              " '8\\tcmn\\t密码是\"Muiriel\"。',\n",
              " '9\\tcmn\\t我很快就會回來。',\n",
              " '10\\tcmn\\t我不知道。']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = open('../../corpus/sentences.csv', encoding='utf8').read().strip()\n",
        "dataset = dataset.split('\\n')\n",
        "dataset[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdR8vTjb8lAp"
      },
      "source": [
        "Run the code to split the fields and remove possible whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHoOKQUd8lAq",
        "outputId": "08f30ae0-8da2-40b5-b7d6-77d1a2dd9c8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('1', 'cmn', '我們試試看！'), ('2', 'cmn', '我该去睡觉了。'), ('3', 'cmn', '你在干什麼啊？')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = list(map(lambda x: tuple(x.split('\\t')), dataset))\n",
        "dataset = list(map(lambda x: tuple(map(str.strip, x)), dataset))\n",
        "dataset[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CcIC0Ds8lAq"
      },
      "source": [
        "Write the code to extract the French, English, and Swedish texts. You will call the resulting dataset: `dataset_small`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9fxgyjA8lAq"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/corpus/mini.tsv'\n",
        "import csv\n",
        "with open(path, encoding = 'UTF-8') as f:\n",
        "  dataset_small = f.read().strip().split('\\n')\n",
        "  dataset_small = list(map(lambda x: tuple(x.split('\\t')), dataset_small))\n",
        "  dataset_small = list(map(lambda x: tuple(map(str.strip, x)), dataset_small))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvyIbgqm8lAr",
        "outputId": "5c6e7e98-c8d2-40ba-ac85-bb42a0cdbf53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1482', 'eng', \"I don't speak Japanese.\"),\n",
              " ('1598', 'eng', \"I don't want to spend the rest of my life regretting it.\"),\n",
              " ('1632', 'eng', 'The cost of life increased drastically.'),\n",
              " ('1864', 'eng', \"She's really smart, isn't she?\"),\n",
              " ('2019',\n",
              "  'eng',\n",
              "  'The news article painted the defendant as a guilty man, even though he had been proven innocent.')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset_small[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfRo8m3I8lAs"
      },
      "source": [
        "### Functions to Count Characters Ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTOxHFw98lAs"
      },
      "source": [
        "Write a function `count_chars(string, lc=True)` to count characters (unigrams) of a string. You will set the text in lowercase if `lc` is set to `True`. As in CLD3, you will return the relative frequencies of the unigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2y8QQxn8lAt"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "def count_chars(text, lc = True):\n",
        "  if lc:\n",
        "    text = text.lower() \n",
        "  return {k : v/len(text) for k,v in Counter(text).items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counth_chars(\"hejhej jag heter Nils\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dggYx6O4DAsQ",
        "outputId": "d60560fd-8c56-4e64-e915-e6ee5af88bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'h': 0.16666666666666666,\n",
              " 'e': 0.2222222222222222,\n",
              " 'j': 0.16666666666666666,\n",
              " 'a': 0.05555555555555555,\n",
              " 'g': 0.05555555555555555,\n",
              " 't': 0.05555555555555555,\n",
              " 'r': 0.05555555555555555,\n",
              " 'n': 0.05555555555555555,\n",
              " 'i': 0.05555555555555555,\n",
              " 'l': 0.05555555555555555,\n",
              " 's': 0.05555555555555555}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEcfT7RQ8lAt"
      },
      "source": [
        "Write a function `count_bigrams(string, lc=True)` to count the characters bigrams of a string. You will set the text in lowercase if `lc` is set to `True`. As in CLD3, you will return the relative frequencies of the bigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TeiW7P98lAt"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "def count_bigrams(text, lc = True):\n",
        "    if lc:\n",
        "      text = text.lower()\n",
        "    #text = re.sub('\\p{z}', '', text)\n",
        "    words = text\n",
        "    bigrams = []\n",
        "    for i in range(len(words) - 1):\n",
        "        bigrams.append(words[i] + words[i + 1])\n",
        "    frequency_bigrams = {}\n",
        "    for i in range(len(words) - 1):\n",
        "        if bigrams[i] in frequency_bigrams:\n",
        "            frequency_bigrams[bigrams[i]] += 1\n",
        "        else:\n",
        "            frequency_bigrams[bigrams[i]] = 1\n",
        "    return {k : v / sum(frequency_bigrams.values()) for k,v in frequency_bigrams.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_bigrams(\"hejhej jag heter Nils\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtrFmLudwPaO",
        "outputId": "611db15f-167d-4545-e9d8-f2e13a3ec19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'he': 0.15,\n",
              " 'ej': 0.1,\n",
              " 'jh': 0.05,\n",
              " 'j ': 0.05,\n",
              " ' j': 0.05,\n",
              " 'ja': 0.05,\n",
              " 'ag': 0.05,\n",
              " 'g ': 0.05,\n",
              " ' h': 0.05,\n",
              " 'et': 0.05,\n",
              " 'te': 0.05,\n",
              " 'er': 0.05,\n",
              " 'r ': 0.05,\n",
              " ' n': 0.05,\n",
              " 'ni': 0.05,\n",
              " 'il': 0.05,\n",
              " 'ls': 0.05}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHWZ9eBq8lAt"
      },
      "source": [
        "Write a function `count_trigrams(string, lc=True)` to count the characters trigrams of a string. You will set the text in lowercase if `lc` is set to `True`. As in CLD3, you will return the relative frequencies of the trigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zyW4zLl8lAu"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "def count_trigrams(text, lc = True):\n",
        "  if lc:\n",
        "    text = text.lower()\n",
        "  words = text\n",
        "  trigrams = [words[idx:idx + 3] for idx in range(len(words) - 2)]\n",
        "  frequencies = {}\n",
        "  for trigram in trigrams:\n",
        "      if trigram in frequencies:\n",
        "          frequencies[trigram] += 1\n",
        "      else:\n",
        "          frequencies[trigram] = 1\n",
        "  return {k : v / sum(frequencies.values()) for k,v in frequencies.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_trigrams(\"hejhej jag heter Nils\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raixukfkyuM6",
        "outputId": "71b18fcd-2d14-400d-9b80-95ff85f660e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hej': 0.10526315789473684,\n",
              " 'ejh': 0.05263157894736842,\n",
              " 'jhe': 0.05263157894736842,\n",
              " 'ej ': 0.05263157894736842,\n",
              " 'j j': 0.05263157894736842,\n",
              " ' ja': 0.05263157894736842,\n",
              " 'jag': 0.05263157894736842,\n",
              " 'ag ': 0.05263157894736842,\n",
              " 'g h': 0.05263157894736842,\n",
              " ' he': 0.05263157894736842,\n",
              " 'het': 0.05263157894736842,\n",
              " 'ete': 0.05263157894736842,\n",
              " 'ter': 0.05263157894736842,\n",
              " 'er ': 0.05263157894736842,\n",
              " 'r n': 0.05263157894736842,\n",
              " ' ni': 0.05263157894736842,\n",
              " 'nil': 0.05263157894736842,\n",
              " 'ils': 0.05263157894736842}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX_XKg978lAu",
        "outputId": "2e38e6a2-1b7d-455f-fe74-b7a1d131202d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l': 0.05,\n",
              " 'e': 0.1,\n",
              " 't': 0.15,\n",
              " \"'\": 0.05,\n",
              " 's': 0.1,\n",
              " ' ': 0.1,\n",
              " 'r': 0.05,\n",
              " 'y': 0.05,\n",
              " 'o': 0.05,\n",
              " 'm': 0.05,\n",
              " 'h': 0.05,\n",
              " 'i': 0.05,\n",
              " 'n': 0.05,\n",
              " 'g': 0.05,\n",
              " '.': 0.05}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "count_chars(\"Let's try something.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Q2tC518lAu",
        "outputId": "ea50152d-9c40-4a4d-ec8c-9320692c942a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'le': 0.05263157894736842,\n",
              " 'et': 0.10526315789473684,\n",
              " \"t'\": 0.05263157894736842,\n",
              " \"'s\": 0.05263157894736842,\n",
              " 's ': 0.05263157894736842,\n",
              " ' t': 0.05263157894736842,\n",
              " 'tr': 0.05263157894736842,\n",
              " 'ry': 0.05263157894736842,\n",
              " 'y ': 0.05263157894736842,\n",
              " ' s': 0.05263157894736842,\n",
              " 'so': 0.05263157894736842,\n",
              " 'om': 0.05263157894736842,\n",
              " 'me': 0.05263157894736842,\n",
              " 'th': 0.05263157894736842,\n",
              " 'hi': 0.05263157894736842,\n",
              " 'in': 0.05263157894736842,\n",
              " 'ng': 0.05263157894736842,\n",
              " 'g.': 0.05263157894736842}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "count_bigrams(\"Let's try something.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL4pFifD8lAv",
        "outputId": "0a9453c2-ee31-4c6e-d98d-4e60982a11f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'let': 0.05555555555555555,\n",
              " \"et'\": 0.05555555555555555,\n",
              " \"t's\": 0.05555555555555555,\n",
              " \"'s \": 0.05555555555555555,\n",
              " 's t': 0.05555555555555555,\n",
              " ' tr': 0.05555555555555555,\n",
              " 'try': 0.05555555555555555,\n",
              " 'ry ': 0.05555555555555555,\n",
              " 'y s': 0.05555555555555555,\n",
              " ' so': 0.05555555555555555,\n",
              " 'som': 0.05555555555555555,\n",
              " 'ome': 0.05555555555555555,\n",
              " 'met': 0.05555555555555555,\n",
              " 'eth': 0.05555555555555555,\n",
              " 'thi': 0.05555555555555555,\n",
              " 'hin': 0.05555555555555555,\n",
              " 'ing': 0.05555555555555555,\n",
              " 'ng.': 0.05555555555555555}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "count_trigrams(\"Let's try something.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLXd2-Ip8lAv"
      },
      "source": [
        "### Counting the ngrams in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MPgSpk78lAv"
      },
      "source": [
        "You will now extract the features from each text. For this, add the character, bigram, and trigram relative frequencies to the texts using this format:\n",
        "`(text_id, language_id, text, char_cnt, bigram_cnt, trigram_cnt)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2PoTyZY8lAv"
      },
      "source": [
        "From the datapoint:\n",
        "`('1276', 'eng', \"Let's try something.\")`,\n",
        "you must return:\n",
        "\n",
        "`('1276', 'eng', \"Let's try something.\", \n",
        "  {'l': 0.05, 'e': 0.1, 't': 0.15, \"'\": 0.05, 's': 0.1, ' ': 0.1, 'r': 0.05, 'y': 0.05, 'o': 0.05, 'm': 0.05, 'h': 0.05, 'i': 0.05, 'n': 0.05, 'g': 0.05, '.': 0.05},\n",
        "  {'le': 0.05263157894736842, 'et': 0.10526315789473684, \"t'\": 0.05263157894736842, \"'s\": 0.05263157894736842, 's ': 0.05263157894736842, ' t': 0.05263157894736842, 'tr': 0.05263157894736842, 'ry': 0.05263157894736842, 'y ': 0.05263157894736842, ' s': 0.05263157894736842, 'so': 0.05263157894736842, 'om': 0.05263157894736842, 'me': 0.05263157894736842, 'th': 0.05263157894736842, 'hi': 0.05263157894736842, 'in': 0.05263157894736842, 'ng': 0.05263157894736842, 'g.': 0.05263157894736842},\n",
        "  {'let': 0.05555555555555555, \"et'\": 0.05555555555555555, \"t's\": 0.05555555555555555, \"'s \": 0.05555555555555555, 's t': 0.05555555555555555, ' tr': 0.05555555555555555, 'try': 0.05555555555555555, 'ry ': 0.05555555555555555, 'y s': 0.05555555555555555, ' so': 0.05555555555555555, 'som': 0.05555555555555555, 'ome': 0.05555555555555555, 'met': 0.05555555555555555, 'eth': 0.05555555555555555, 'thi': 0.05555555555555555, 'hin': 0.05555555555555555, 'ing': 0.05555555555555555, 'ng.': 0.05555555555555555})`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nydYTX98lAw"
      },
      "source": [
        "You will store the extracted features in a list that you will call `dataset_small_feat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt1kYSaf8lAw"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "dataset_small_feat = list(map(lambda x: x + (count_chars(x[-1]), count_bigrams(x[-1]), count_trigrams(x[-1])), \n",
        "                              dataset_small))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cmGvGw68lAw"
      },
      "source": [
        "We only compute the unigrams and bigrams as most students have slow machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNgWmaE58lAw"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPKq2vFt8lAw",
        "outputId": "b381b96d-16b6-4193-8c24-f79f5b7eb0e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1482',\n",
              "  'eng',\n",
              "  \"I don't speak Japanese.\",\n",
              "  {'i': 0.043478260869565216,\n",
              "   ' ': 0.13043478260869565,\n",
              "   'd': 0.043478260869565216,\n",
              "   'o': 0.043478260869565216,\n",
              "   'n': 0.08695652173913043,\n",
              "   \"'\": 0.043478260869565216,\n",
              "   't': 0.043478260869565216,\n",
              "   's': 0.08695652173913043,\n",
              "   'p': 0.08695652173913043,\n",
              "   'e': 0.13043478260869565,\n",
              "   'a': 0.13043478260869565,\n",
              "   'k': 0.043478260869565216,\n",
              "   'j': 0.043478260869565216,\n",
              "   '.': 0.043478260869565216},\n",
              "  {'i ': 0.045454545454545456,\n",
              "   ' d': 0.045454545454545456,\n",
              "   'do': 0.045454545454545456,\n",
              "   'on': 0.045454545454545456,\n",
              "   \"n'\": 0.045454545454545456,\n",
              "   \"'t\": 0.045454545454545456,\n",
              "   't ': 0.045454545454545456,\n",
              "   ' s': 0.045454545454545456,\n",
              "   'sp': 0.045454545454545456,\n",
              "   'pe': 0.045454545454545456,\n",
              "   'ea': 0.045454545454545456,\n",
              "   'ak': 0.045454545454545456,\n",
              "   'k ': 0.045454545454545456,\n",
              "   ' j': 0.045454545454545456,\n",
              "   'ja': 0.045454545454545456,\n",
              "   'ap': 0.045454545454545456,\n",
              "   'pa': 0.045454545454545456,\n",
              "   'an': 0.045454545454545456,\n",
              "   'ne': 0.045454545454545456,\n",
              "   'es': 0.045454545454545456,\n",
              "   'se': 0.045454545454545456,\n",
              "   'e.': 0.045454545454545456},\n",
              "  {'i d': 0.047619047619047616,\n",
              "   ' do': 0.047619047619047616,\n",
              "   'don': 0.047619047619047616,\n",
              "   \"on'\": 0.047619047619047616,\n",
              "   \"n't\": 0.047619047619047616,\n",
              "   \"'t \": 0.047619047619047616,\n",
              "   't s': 0.047619047619047616,\n",
              "   ' sp': 0.047619047619047616,\n",
              "   'spe': 0.047619047619047616,\n",
              "   'pea': 0.047619047619047616,\n",
              "   'eak': 0.047619047619047616,\n",
              "   'ak ': 0.047619047619047616,\n",
              "   'k j': 0.047619047619047616,\n",
              "   ' ja': 0.047619047619047616,\n",
              "   'jap': 0.047619047619047616,\n",
              "   'apa': 0.047619047619047616,\n",
              "   'pan': 0.047619047619047616,\n",
              "   'ane': 0.047619047619047616,\n",
              "   'nes': 0.047619047619047616,\n",
              "   'ese': 0.047619047619047616,\n",
              "   'se.': 0.047619047619047616}),\n",
              " ('1598',\n",
              "  'eng',\n",
              "  \"I don't want to spend the rest of my life regretting it.\",\n",
              "  {'i': 0.07142857142857142,\n",
              "   ' ': 0.19642857142857142,\n",
              "   'd': 0.03571428571428571,\n",
              "   'o': 0.05357142857142857,\n",
              "   'n': 0.07142857142857142,\n",
              "   \"'\": 0.017857142857142856,\n",
              "   't': 0.14285714285714285,\n",
              "   'w': 0.017857142857142856,\n",
              "   'a': 0.017857142857142856,\n",
              "   's': 0.03571428571428571,\n",
              "   'p': 0.017857142857142856,\n",
              "   'e': 0.10714285714285714,\n",
              "   'h': 0.017857142857142856,\n",
              "   'r': 0.05357142857142857,\n",
              "   'f': 0.03571428571428571,\n",
              "   'm': 0.017857142857142856,\n",
              "   'y': 0.017857142857142856,\n",
              "   'l': 0.017857142857142856,\n",
              "   'g': 0.03571428571428571,\n",
              "   '.': 0.017857142857142856},\n",
              "  {'i ': 0.01818181818181818,\n",
              "   ' d': 0.01818181818181818,\n",
              "   'do': 0.01818181818181818,\n",
              "   'on': 0.01818181818181818,\n",
              "   \"n'\": 0.01818181818181818,\n",
              "   \"'t\": 0.01818181818181818,\n",
              "   't ': 0.05454545454545454,\n",
              "   ' w': 0.01818181818181818,\n",
              "   'wa': 0.01818181818181818,\n",
              "   'an': 0.01818181818181818,\n",
              "   'nt': 0.01818181818181818,\n",
              "   ' t': 0.03636363636363636,\n",
              "   'to': 0.01818181818181818,\n",
              "   'o ': 0.01818181818181818,\n",
              "   ' s': 0.01818181818181818,\n",
              "   'sp': 0.01818181818181818,\n",
              "   'pe': 0.01818181818181818,\n",
              "   'en': 0.01818181818181818,\n",
              "   'nd': 0.01818181818181818,\n",
              "   'd ': 0.01818181818181818,\n",
              "   'th': 0.01818181818181818,\n",
              "   'he': 0.01818181818181818,\n",
              "   'e ': 0.03636363636363636,\n",
              "   ' r': 0.03636363636363636,\n",
              "   're': 0.05454545454545454,\n",
              "   'es': 0.01818181818181818,\n",
              "   'st': 0.01818181818181818,\n",
              "   ' o': 0.01818181818181818,\n",
              "   'of': 0.01818181818181818,\n",
              "   'f ': 0.01818181818181818,\n",
              "   ' m': 0.01818181818181818,\n",
              "   'my': 0.01818181818181818,\n",
              "   'y ': 0.01818181818181818,\n",
              "   ' l': 0.01818181818181818,\n",
              "   'li': 0.01818181818181818,\n",
              "   'if': 0.01818181818181818,\n",
              "   'fe': 0.01818181818181818,\n",
              "   'eg': 0.01818181818181818,\n",
              "   'gr': 0.01818181818181818,\n",
              "   'et': 0.01818181818181818,\n",
              "   'tt': 0.01818181818181818,\n",
              "   'ti': 0.01818181818181818,\n",
              "   'in': 0.01818181818181818,\n",
              "   'ng': 0.01818181818181818,\n",
              "   'g ': 0.01818181818181818,\n",
              "   ' i': 0.01818181818181818,\n",
              "   'it': 0.01818181818181818,\n",
              "   't.': 0.01818181818181818},\n",
              "  {'i d': 0.018518518518518517,\n",
              "   ' do': 0.018518518518518517,\n",
              "   'don': 0.018518518518518517,\n",
              "   \"on'\": 0.018518518518518517,\n",
              "   \"n't\": 0.018518518518518517,\n",
              "   \"'t \": 0.018518518518518517,\n",
              "   't w': 0.018518518518518517,\n",
              "   ' wa': 0.018518518518518517,\n",
              "   'wan': 0.018518518518518517,\n",
              "   'ant': 0.018518518518518517,\n",
              "   'nt ': 0.018518518518518517,\n",
              "   't t': 0.018518518518518517,\n",
              "   ' to': 0.018518518518518517,\n",
              "   'to ': 0.018518518518518517,\n",
              "   'o s': 0.018518518518518517,\n",
              "   ' sp': 0.018518518518518517,\n",
              "   'spe': 0.018518518518518517,\n",
              "   'pen': 0.018518518518518517,\n",
              "   'end': 0.018518518518518517,\n",
              "   'nd ': 0.018518518518518517,\n",
              "   'd t': 0.018518518518518517,\n",
              "   ' th': 0.018518518518518517,\n",
              "   'the': 0.018518518518518517,\n",
              "   'he ': 0.018518518518518517,\n",
              "   'e r': 0.037037037037037035,\n",
              "   ' re': 0.037037037037037035,\n",
              "   'res': 0.018518518518518517,\n",
              "   'est': 0.018518518518518517,\n",
              "   'st ': 0.018518518518518517,\n",
              "   't o': 0.018518518518518517,\n",
              "   ' of': 0.018518518518518517,\n",
              "   'of ': 0.018518518518518517,\n",
              "   'f m': 0.018518518518518517,\n",
              "   ' my': 0.018518518518518517,\n",
              "   'my ': 0.018518518518518517,\n",
              "   'y l': 0.018518518518518517,\n",
              "   ' li': 0.018518518518518517,\n",
              "   'lif': 0.018518518518518517,\n",
              "   'ife': 0.018518518518518517,\n",
              "   'fe ': 0.018518518518518517,\n",
              "   'reg': 0.018518518518518517,\n",
              "   'egr': 0.018518518518518517,\n",
              "   'gre': 0.018518518518518517,\n",
              "   'ret': 0.018518518518518517,\n",
              "   'ett': 0.018518518518518517,\n",
              "   'tti': 0.018518518518518517,\n",
              "   'tin': 0.018518518518518517,\n",
              "   'ing': 0.018518518518518517,\n",
              "   'ng ': 0.018518518518518517,\n",
              "   'g i': 0.018518518518518517,\n",
              "   ' it': 0.018518518518518517,\n",
              "   'it.': 0.018518518518518517})]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "dataset_small_feat[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgqLMTM78lAx"
      },
      "source": [
        "The unigram frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ShTDwT8lAx",
        "outputId": "c449a010-2cb4-4417-93c6-1172ffc908ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('i', 0.043478260869565216), (' ', 0.13043478260869565), ('d', 0.043478260869565216), ('o', 0.043478260869565216), ('n', 0.08695652173913043), (\"'\", 0.043478260869565216), ('t', 0.043478260869565216), ('s', 0.08695652173913043), ('p', 0.08695652173913043), ('e', 0.13043478260869565), ('a', 0.13043478260869565), ('k', 0.043478260869565216), ('j', 0.043478260869565216), ('.', 0.043478260869565216)])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "dataset_small_feat[0][3].items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbyrttc68lAx"
      },
      "source": [
        "The bigram frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk1FMPl38lAx",
        "outputId": "8cb15637-6a9c-4b59-9be4-3f55d83f95a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('i ', 0.045454545454545456), (' d', 0.045454545454545456), ('do', 0.045454545454545456), ('on', 0.045454545454545456), (\"n'\", 0.045454545454545456), (\"'t\", 0.045454545454545456), ('t ', 0.045454545454545456), (' s', 0.045454545454545456), ('sp', 0.045454545454545456), ('pe', 0.045454545454545456), ('ea', 0.045454545454545456), ('ak', 0.045454545454545456), ('k ', 0.045454545454545456), (' j', 0.045454545454545456), ('ja', 0.045454545454545456), ('ap', 0.045454545454545456), ('pa', 0.045454545454545456), ('an', 0.045454545454545456), ('ne', 0.045454545454545456), ('es', 0.045454545454545456), ('se', 0.045454545454545456), ('e.', 0.045454545454545456)])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "dataset_small_feat[0][4].items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACrECPwW8lAy"
      },
      "source": [
        "## Programming: Building $\\mathbf{X}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m3XXdwo8lAy"
      },
      "source": [
        "You will now build the $\\mathbf{X}$ matrix. In this assignment, you will only consider unigrams to speed up the training step. This means that you will set aside the character bigrams and trigrams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty6IR2r98lAy"
      },
      "source": [
        "When you are done with the lab requirements, feel free to improve the program and include bigrams and trigrams. To add bigrams, a possible method is to add the bigram dictionary to the unigram one using update and then to extract the resulting dictionary. You can easily extend this to trigrams. Feel free to use another method if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV6e4bBA8lAy"
      },
      "outputs": [],
      "source": [
        "INCLUDE_BIGRAMS = False\n",
        "if INCLUDE_BIGRAMS:\n",
        "    for i in range(len(dataset_small_feat)):\n",
        "        dataset_small_feat[i][3].update(dataset_small_feat[i][4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PdRHex08lAz"
      },
      "source": [
        "### Vectorizing the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-xVINFw8lAz"
      },
      "source": [
        "The CLD3 architecture uses embeddings. In this lab, we will simplify it and we will use a feature vector instead consisting of the character frequencies. For example, you will represent the text:\n",
        "\n",
        "`\"Let's try something.\"`\n",
        "\n",
        "with:\n",
        "\n",
        "`{'l': 0.05, 'e': 0.1, 't': 0.15, \"'\": 0.05, 's': 0.1, ' ': 0.1, \n",
        " 'r': 0.05, 'y': 0.05, 'o': 0.05, 'm': 0.05, 'h': 0.05, 'i': 0.05, \n",
        " 'n': 0.05, 'g': 0.05, '.': 0.05}`\n",
        "\n",
        "To create the $\\mathbf{X}$ matrix, we need to transform the dictionaries of `dataset_small` into numerical vectors. The `DictVectorizer` class from the scikit-learn library, see here [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html], has two methods, `fit()` and `transform()`, and a combination of both `fit_transform()` to convert dictionaries into such vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ufEgnbU8lAz"
      },
      "source": [
        "You will now write the code to:\n",
        "\n",
        "1. Extract the character frequency dictionaries from `dataset_small` corresponding to its 3rd index and set them in a list;\n",
        "2. Convert the list of dictionaries into an $\\mathbf{X}$ matrix using `DictVectorizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVsNqk1N8lA0"
      },
      "source": [
        "#### Extracting the character frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kshfPgf58lA0"
      },
      "source": [
        "Produce a new list of datapoints with the unigrams only. Each item in this list will be a dictionary. You will call it `X_cat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-WyBXDW8lA0"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "X_cat = [row[3] for row in dataset_small_feat] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUkjUHQ8lA0",
        "outputId": "1e6e92a3-bc50-4974-dbbe-30719242844b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'i': 0.043478260869565216,\n",
              "  ' ': 0.13043478260869565,\n",
              "  'd': 0.043478260869565216,\n",
              "  'o': 0.043478260869565216,\n",
              "  'n': 0.08695652173913043,\n",
              "  \"'\": 0.043478260869565216,\n",
              "  't': 0.043478260869565216,\n",
              "  's': 0.08695652173913043,\n",
              "  'p': 0.08695652173913043,\n",
              "  'e': 0.13043478260869565,\n",
              "  'a': 0.13043478260869565,\n",
              "  'k': 0.043478260869565216,\n",
              "  'j': 0.043478260869565216,\n",
              "  '.': 0.043478260869565216},\n",
              " {'i': 0.07142857142857142,\n",
              "  ' ': 0.19642857142857142,\n",
              "  'd': 0.03571428571428571,\n",
              "  'o': 0.05357142857142857,\n",
              "  'n': 0.07142857142857142,\n",
              "  \"'\": 0.017857142857142856,\n",
              "  't': 0.14285714285714285,\n",
              "  'w': 0.017857142857142856,\n",
              "  'a': 0.017857142857142856,\n",
              "  's': 0.03571428571428571,\n",
              "  'p': 0.017857142857142856,\n",
              "  'e': 0.10714285714285714,\n",
              "  'h': 0.017857142857142856,\n",
              "  'r': 0.05357142857142857,\n",
              "  'f': 0.03571428571428571,\n",
              "  'm': 0.017857142857142856,\n",
              "  'y': 0.017857142857142856,\n",
              "  'l': 0.017857142857142856,\n",
              "  'g': 0.03571428571428571,\n",
              "  '.': 0.017857142857142856}]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "X_cat[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Cu1blj8lA1"
      },
      "source": [
        "#### Vectorize `X_cat`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MTUbtCE8lBA"
      },
      "source": [
        "Convert you `X_cat` matrix into a numerical representation using `DictVectorizer`: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html. Call the result `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8uK1v-88lBQ"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "v = DictVectorizer(sparse=False)\n",
        "X = v.fit_transform(X_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_rY_X7Y8lBR",
        "outputId": "562594b6-6f6d-4384-cd50-3ebd8600baa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13043478, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04347826, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04347826, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.13043478, 0.        , 0.        ,\n",
              "        0.04347826, 0.13043478, 0.        , 0.        , 0.        ,\n",
              "        0.04347826, 0.04347826, 0.04347826, 0.        , 0.        ,\n",
              "        0.08695652, 0.04347826, 0.08695652, 0.        , 0.        ,\n",
              "        0.08695652, 0.04347826, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.19642857, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01785714, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01785714, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01785714, 0.        , 0.        ,\n",
              "        0.03571429, 0.10714286, 0.03571429, 0.03571429, 0.01785714,\n",
              "        0.07142857, 0.        , 0.        , 0.01785714, 0.01785714,\n",
              "        0.07142857, 0.05357143, 0.01785714, 0.        , 0.05357143,\n",
              "        0.03571429, 0.14285714, 0.        , 0.        , 0.01785714,\n",
              "        0.        , 0.01785714, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.12820513, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.02564103, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07692308, 0.        , 0.07692308,\n",
              "        0.05128205, 0.1025641 , 0.05128205, 0.        , 0.02564103,\n",
              "        0.07692308, 0.        , 0.        , 0.07692308, 0.        ,\n",
              "        0.02564103, 0.05128205, 0.        , 0.        , 0.05128205,\n",
              "        0.07692308, 0.07692308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.02564103, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.13333333, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.06666667, 0.        , 0.        , 0.        , 0.03333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03333333, 0.        , 0.06666667, 0.        , 0.        ,\n",
              "        0.        , 0.1       , 0.        , 0.        , 0.06666667,\n",
              "        0.03333333, 0.        , 0.        , 0.06666667, 0.03333333,\n",
              "        0.03333333, 0.        , 0.        , 0.        , 0.06666667,\n",
              "        0.16666667, 0.06666667, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03333333, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01041667,\n",
              "        0.        , 0.01041667, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07291667, 0.01041667, 0.02083333,\n",
              "        0.04166667, 0.14583333, 0.01041667, 0.02083333, 0.0625    ,\n",
              "        0.04166667, 0.        , 0.        , 0.02083333, 0.01041667,\n",
              "        0.11458333, 0.03125   , 0.02083333, 0.        , 0.02083333,\n",
              "        0.02083333, 0.08333333, 0.02083333, 0.02083333, 0.01041667,\n",
              "        0.        , 0.01041667, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "X[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSAGNlYY8lBR"
      },
      "source": [
        "## Programming: Building $\\mathbf{y}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JEbQSkD8lBR"
      },
      "source": [
        "You will now convert the list of language symbols into a $\\mathbf{y}$ vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ6C3BW68lBR"
      },
      "source": [
        "Extract the language symbols from `dataset_small_feat` and call the resulting list `y_cat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFSDejKi8lBR"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "y_cat = [row[1] for row in dataset_small_feat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xyxQaTo8lBS",
        "outputId": "0c192c7e-419e-472f-bed5-d130f0f0e18c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eng', 'eng', 'eng', 'eng', 'eng']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "y_cat[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxQq_Tgr8lBS"
      },
      "source": [
        "Extract the set of language symbols and name it `y_symbols`. Then build two indices mapping the symbols to integers and the integers to symbols. Both indices will be dictionaries that you will call: `lang2idx`and `idx2lang`. Such a conversion is not necessary with sklearn. We do it because many other many machine-learning toolkits (keras or pytorch) require a numerical $\\mathbf{y}$ vector and to learn how to carry out this conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa5NeUw-8lBT"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "lang2idx = {lang : i for i, lang in enumerate(set(y_cat))}\n",
        "idx2lang = {v:k for k,v in lang2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKqc9sIF8lBT",
        "outputId": "594974f0-bf9a-4be4-af01-f0b6c8943770"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'swe', 1: 'fra', 2: 'eng'}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "idx2lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYE7YWfH8lBU",
        "outputId": "aa2419eb-a5e2-4e62-8a94-62141c575675"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'swe': 0, 'fra': 1, 'eng': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "lang2idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACmQdiko8lBU"
      },
      "source": [
        "Convert your `y_cat` vector into a numerical vector. Call this vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHN02sWD8lBU"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "y = [lang2idx[lang] for lang in y_cat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkImoIyV8lBU",
        "outputId": "e4157a21-33f8-40c5-d130-4912b22b80b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 2, 2, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj7hLxxI8lBU"
      },
      "source": [
        "## Programming: Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVtHjyXY8lBV"
      },
      "source": [
        "Create a neural network using sklearn with a hidden layer of 50 nodes and a relu activation layer: https://scikit-learn.org/stable/modules/neural_networks_supervised.html. Set the maximal number of iterations to 5, in the beginning, and verbose to True. Use the default values for the rest. You will call your classifier `clf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n91TphE78lBV"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0RU0EAr8lBV",
        "outputId": "d43e234c-b088-49ae-dfcf-cdffa328b2da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ7yG2hx8lBV"
      },
      "source": [
        "### Training and Validation Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4-zQWqu8lBV"
      },
      "source": [
        "You will now split the dataset into a training and validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05SkkqQc8lBV"
      },
      "source": [
        "#### We shuffle the indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppLjkw--8lBW",
        "outputId": "ee1fb328-739c-4f20-d400-1d2e6e16828e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2156, 13157, 31555, 13501, 3653, 27203, 31426, 13153, 10444, 26982]\n"
          ]
        }
      ],
      "source": [
        "indices = list(range(X.shape[0]))\n",
        "np.random.shuffle(indices)\n",
        "print(indices[:10])\n",
        "X = X[indices, :]\n",
        "y = np.array(y)[indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ugzBZhD8lBX"
      },
      "source": [
        "#### We split the dataset\n",
        "We use a training set of 80% and a validation set of 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z2hQsO68lBY"
      },
      "outputs": [],
      "source": [
        "training_examples = int(X.shape[0] * 0.8)\n",
        "\n",
        "X_train = X[:training_examples, :]\n",
        "y_train = y[:training_examples]\n",
        "\n",
        "X_val = X[training_examples:, :]\n",
        "y_val = y[training_examples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "jibbJcRS8lBY"
      },
      "source": [
        "### Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ci0ZyMG8lBZ"
      },
      "source": [
        "Fit the model on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHn5Zryx8lBZ",
        "outputId": "f6059e3e-8558-4af5-d5ec-dc4381fcdcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.00398268\n",
            "Iteration 2, loss = 0.76552054\n",
            "Iteration 3, loss = 0.51252072\n",
            "Iteration 4, loss = 0.36670322\n",
            "Iteration 5, loss = 0.28836159\n",
            "Iteration 6, loss = 0.24176861\n",
            "Iteration 7, loss = 0.21130848\n",
            "Iteration 8, loss = 0.18975510\n",
            "Iteration 9, loss = 0.17397720\n",
            "Iteration 10, loss = 0.16212691\n",
            "Iteration 11, loss = 0.15293940\n",
            "Iteration 12, loss = 0.14608317\n",
            "Iteration 13, loss = 0.14065484\n",
            "Iteration 14, loss = 0.13591432\n",
            "Iteration 15, loss = 0.13221521\n",
            "Iteration 16, loss = 0.12903083\n",
            "Iteration 17, loss = 0.12644320\n",
            "Iteration 18, loss = 0.12415150\n",
            "Iteration 19, loss = 0.12232722\n",
            "Iteration 20, loss = 0.12062701\n",
            "Iteration 21, loss = 0.11911164\n",
            "Iteration 22, loss = 0.11790251\n",
            "Iteration 23, loss = 0.11651380\n",
            "Iteration 24, loss = 0.11527138\n",
            "Iteration 25, loss = 0.11448057\n",
            "Iteration 26, loss = 0.11375886\n",
            "Iteration 27, loss = 0.11286386\n",
            "Iteration 28, loss = 0.11227028\n",
            "Iteration 29, loss = 0.11149498\n",
            "Iteration 30, loss = 0.11113302\n",
            "Iteration 31, loss = 0.11046939\n",
            "Iteration 32, loss = 0.10993973\n",
            "Iteration 33, loss = 0.10958342\n",
            "Iteration 34, loss = 0.10901048\n",
            "Iteration 35, loss = 0.10876440\n",
            "Iteration 36, loss = 0.10830148\n",
            "Iteration 37, loss = 0.10823450\n",
            "Iteration 38, loss = 0.10783827\n",
            "Iteration 39, loss = 0.10750288\n",
            "Iteration 40, loss = 0.10740659\n",
            "Iteration 41, loss = 0.10683638\n",
            "Iteration 42, loss = 0.10679689\n",
            "Iteration 43, loss = 0.10646466\n",
            "Iteration 44, loss = 0.10614813\n",
            "Iteration 45, loss = 0.10580109\n",
            "Iteration 46, loss = 0.10584160\n",
            "Iteration 47, loss = 0.10584976\n",
            "Iteration 48, loss = 0.10510786\n",
            "Iteration 49, loss = 0.10509568\n",
            "Iteration 50, loss = 0.10468552\n",
            "Iteration 51, loss = 0.10477430\n",
            "Iteration 52, loss = 0.10441174\n",
            "Iteration 53, loss = 0.10425132\n",
            "Iteration 54, loss = 0.10414870\n",
            "Iteration 55, loss = 0.10386100\n",
            "Iteration 56, loss = 0.10368752\n",
            "Iteration 57, loss = 0.10371181\n",
            "Iteration 58, loss = 0.10345699\n",
            "Iteration 59, loss = 0.10308003\n",
            "Iteration 60, loss = 0.10298245\n",
            "Iteration 61, loss = 0.10294484\n",
            "Iteration 62, loss = 0.10242934\n",
            "Iteration 63, loss = 0.10238328\n",
            "Iteration 64, loss = 0.10225284\n",
            "Iteration 65, loss = 0.10196270\n",
            "Iteration 66, loss = 0.10190059\n",
            "Iteration 67, loss = 0.10178707\n",
            "Iteration 68, loss = 0.10139688\n",
            "Iteration 69, loss = 0.10146483\n",
            "Iteration 70, loss = 0.10151744\n",
            "Iteration 71, loss = 0.10104257\n",
            "Iteration 72, loss = 0.10086453\n",
            "Iteration 73, loss = 0.10079348\n",
            "Iteration 74, loss = 0.10064206\n",
            "Iteration 75, loss = 0.10078073\n",
            "Iteration 76, loss = 0.10053260\n",
            "Iteration 77, loss = 0.10033974\n",
            "Iteration 78, loss = 0.10012486\n",
            "Iteration 79, loss = 0.09974064\n",
            "Iteration 80, loss = 0.09989036\n",
            "Iteration 81, loss = 0.09964811\n",
            "Iteration 82, loss = 0.09955194\n",
            "Iteration 83, loss = 0.09928282\n",
            "Iteration 84, loss = 0.09935303\n",
            "Iteration 85, loss = 0.09916009\n",
            "Iteration 86, loss = 0.09918967\n",
            "Iteration 87, loss = 0.09882262\n",
            "Iteration 88, loss = 0.09867892\n",
            "Iteration 89, loss = 0.09856529\n",
            "Iteration 90, loss = 0.09841992\n",
            "Iteration 91, loss = 0.09815367\n",
            "Iteration 92, loss = 0.09804009\n",
            "Iteration 93, loss = 0.09804851\n",
            "Iteration 94, loss = 0.09805407\n",
            "Iteration 95, loss = 0.09771585\n",
            "Iteration 96, loss = 0.09767280\n",
            "Iteration 97, loss = 0.09726166\n",
            "Iteration 98, loss = 0.09752429\n",
            "Iteration 99, loss = 0.09701916\n",
            "Iteration 100, loss = 0.09701663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Write your code here\n",
        "clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9AXW3Tx8lBZ"
      },
      "source": [
        "## Predicting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHlcnida8lBZ"
      },
      "source": [
        "Predict the `X_val` languages. You will call the result `y_val_pred`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93lGMt6m8lBa"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "y_val_pred = clf.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pBTQam88lBa",
        "outputId": "4d099a86-1a94-4722-b793-28b6d75c5d27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "y_val_pred[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oogU9Zfd8lBa",
        "outputId": "7072a30c-b105-45ad-b0f3-27d915abcfb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 2, 0, 2, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "y_val[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkzmO9rk8lBa"
      },
      "source": [
        "#### Evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVQa8R2S8lBb"
      },
      "source": [
        "Use the `accuracy_score()` function to evaluate your model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt0n6d-E8lBb",
        "outputId": "a3a4316c-eb79-4c8c-9bab-33601402b196"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9610621904237755"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# evaluate the model\n",
        "accuracy_score(y_val, y_val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBpw8yzp8lBb",
        "outputId": "31fc5b24-7bea-4d61-8ba9-3f06315d4051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         swe       0.97      0.96      0.96      1974\n",
            "         fra       0.95      0.96      0.96      2014\n",
            "         eng       0.96      0.97      0.96      3280\n",
            "\n",
            "    accuracy                           0.96      7268\n",
            "   macro avg       0.96      0.96      0.96      7268\n",
            "weighted avg       0.96      0.96      0.96      7268\n",
            "\n",
            "Micro F1: 0.9610621904237755\n",
            "Macro F1 0.9606558779048515\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_val, y_val_pred, target_names=y_symbols))\n",
        "print('Micro F1:', f1_score(y_val, y_val_pred, average='micro'))\n",
        "print('Macro F1', f1_score(y_val, y_val_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR8lMIVt8lBb"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1F2hiPC8lBb",
        "outputId": "d0ad7736-a6fe-482c-dcd2-8d26711b514d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1890,   17,   67],\n",
              "       [  23, 1924,   67],\n",
              "       [  35,   74, 3171]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "confusion_matrix(y_val, y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvQEI0XO8lBc"
      },
      "source": [
        "You may try to increase the number of iterations to improve the score. You may also try change the parameters of the multilayer percetron."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_SZATFi8lBc"
      },
      "source": [
        "## Predict the language of a text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUthsKqn8lBc"
      },
      "source": [
        "Now you will predict the languages of the strings below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPR8JIAC8lBc"
      },
      "outputs": [],
      "source": [
        "docs = [\"Salut les gars !\", \"Hejsan grabbar!\", \"Hello guys!\", \"Hejsan tjejer!\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct0wuxgD8lBc"
      },
      "source": [
        "Create features vectors from this list. Call this matrix `X_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1BSlEc48lBd"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "def featurize(string_list, dictvectorizer):\n",
        "  return list(map(lambda x : x[0], map(dictvectorizer.transform ,map(count_chars, string_list))))\n",
        "\n",
        "X_test = featurize(docs, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh4vm3R98lBd",
        "outputId": "526a65c1-c048-48f9-8492-7ac9eee8f6b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.1875, 0.0625, 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.125 , 0.    , 0.    , 0.    , 0.0625,\n",
              "        0.    , 0.0625, 0.    , 0.    , 0.    , 0.    , 0.125 , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.0625, 0.1875, 0.0625, 0.0625,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
              "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ]),\n",
              " array([0.06666667, 0.06666667, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2       , 0.13333333, 0.        ,\n",
              "        0.        , 0.06666667, 0.        , 0.06666667, 0.06666667,\n",
              "        0.        , 0.06666667, 0.        , 0.        , 0.        ,\n",
              "        0.06666667, 0.        , 0.        , 0.        , 0.13333333,\n",
              "        0.06666667, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ]),\n",
              " array([0.09090909, 0.09090909, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09090909, 0.        , 0.09090909, 0.09090909,\n",
              "        0.        , 0.        , 0.        , 0.18181818, 0.        ,\n",
              "        0.        , 0.09090909, 0.        , 0.        , 0.        ,\n",
              "        0.09090909, 0.        , 0.09090909, 0.        , 0.        ,\n",
              "        0.        , 0.09090909, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ]),\n",
              " array([0.07142857, 0.07142857, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07142857, 0.        , 0.        ,\n",
              "        0.        , 0.21428571, 0.        , 0.        , 0.07142857,\n",
              "        0.        , 0.21428571, 0.        , 0.        , 0.        ,\n",
              "        0.07142857, 0.        , 0.        , 0.        , 0.07142857,\n",
              "        0.07142857, 0.07142857, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ])]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neXdEp0v8lBd"
      },
      "source": [
        "And run the prediction that you will store in a variable called `pred_languages`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wQlr8p58lBd"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "pred_languages = [idx2lang[pred] for pred in clf.predict(X_test)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2skNDA-8lBe",
        "outputId": "9633fbd5-dd11-4c11-96e2-55ee57dd6097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fra', 'swe', 'eng', 'swe']"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "pred_languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MReQWYFU8lBe"
      },
      "source": [
        "## Building the Model with Keras\n",
        "You will now recreate a Keras model with the same architecture as in sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRS4QKlQ8lBe"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tGaFgUwIKmX",
        "outputId": "830a535b-fb97-45fc-c016-ddad0cde7c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29068, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo4ikoKj8lBe"
      },
      "source": [
        "### The Model\n",
        "Create a model identical to the one you created with sklearn. Use the same activation function for the hidden layer and softmax in the last layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I2Jwd7Q8lBf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "model = keras.Sequential([keras.layers.Dense(50, input_shape = (X_train.shape[1], ), activation = 'relu'),\n",
        "                          keras.layers.Dense(3, activation = 'softmax')\n",
        "                          ]\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DIyUla08lBf",
        "outputId": "0981a7aa-e400-41ff-f3b4-16e3ecbe4981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 50)                4850      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,003\n",
            "Trainable params: 5,003\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knl-tN-i8lBf"
      },
      "source": [
        "Compile your network with the loss, optimizer, and metrics arguments. As optimizer, use the same as in sklearn. See here: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK1TBj618lBf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSJzxfT98lBg"
      },
      "source": [
        "Convert the output categories to one-hot vectors. Call the result: `Y_train_cat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf5EF2Ig8lBg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTLS3H4n8lBg"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "Y_train_cat = to_categorical(\n",
        "    y_train, num_classes=3, dtype='float32'\n",
        ")\n",
        "Y_val_cat = to_categorical(\n",
        "    y_val, num_classes=3, dtype='float32'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKwuRmOT8lBg",
        "outputId": "58022b25-b2ab-40b5-e4f8-b2822f8a4efa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "Y_train_cat[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqxXCCGI8lBg"
      },
      "source": [
        "Fit your network on your training set. Use two epochs to start with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh8amZSi8lBh",
        "outputId": "9f7254b8-2adc-4dea-e65e-36e35e4d8ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.1025 - accuracy: 0.9624\n",
            "Epoch 2/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.1021 - accuracy: 0.9622\n",
            "Epoch 3/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.1013 - accuracy: 0.9625\n",
            "Epoch 4/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.1008 - accuracy: 0.9623\n",
            "Epoch 5/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.1001 - accuracy: 0.9635\n",
            "Epoch 6/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0995 - accuracy: 0.9632\n",
            "Epoch 7/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0992 - accuracy: 0.9636\n",
            "Epoch 8/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0985 - accuracy: 0.9631\n",
            "Epoch 9/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0978 - accuracy: 0.9634\n",
            "Epoch 10/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0970 - accuracy: 0.9632\n",
            "Epoch 11/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.9640\n",
            "Epoch 12/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.9640\n",
            "Epoch 13/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0954 - accuracy: 0.9649\n",
            "Epoch 14/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.9648\n",
            "Epoch 15/15\n",
            "909/909 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.9646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d2fd962d0>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "# Write your code here\n",
        "model.fit(X_train, Y_train_cat, epochs = 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_7OciW38lBh"
      },
      "source": [
        "Evaluate your network on `X_val` and `y_val` with the `evaluate()` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l7b83tp8lBh",
        "outputId": "6e5815f9-1cd4-41e7-f076-eb3037c61c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10313791036605835, 0.9620253443717957]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "# Write your code here\n",
        "model.evaluate(X_val, Y_val_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNx_DeHi8lBh"
      },
      "source": [
        "Predict the validation set: `X_val`. Call the result: `Y_val_pred_proba`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bJjNDsS8lBn"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "Y_val_pred_proba = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUhXPhyD8lBs",
        "outputId": "fbaf25f4-6696-4bbb-d56a-eb740f48db1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.0445362e-06, 9.9999058e-01, 2.3804862e-06],\n",
              "       [2.2156986e-05, 9.9962902e-01, 3.4874643e-04],\n",
              "       [1.0000000e+00, 5.4049274e-19, 4.5157749e-21],\n",
              "       [1.0000000e+00, 4.3803317e-09, 1.5293482e-10],\n",
              "       [4.5808003e-04, 2.6849745e-02, 9.7269213e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "Y_val_pred_proba[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQqxlHr58lBs"
      },
      "source": [
        "Extract the categories from the probabilities in `Y_val_pred_proba`. Use the `np.argmax()` function. Call the result `y_val_pred`. Check that the prediction corresponds to the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN8LSte38lBu"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "y_val_pred = [np.argmax(row) for row in Y_val_pred_proba]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "783QUisc8lBu",
        "outputId": "9176d5f9-89ea-4a6c-d70c-a0ad334fe36d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "y_val_pred[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDQYCYwg8lBu",
        "outputId": "33e809e0-14ab-4fc3-f576-752f99c5e709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 2, 0, 2, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "y_val[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUJsjI5d8lBu"
      },
      "source": [
        "Print the evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEQVVnp28lBv",
        "outputId": "055897f0-2fa0-41da-89bd-7b012f98dffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         swe       0.97      0.96      0.96      1974\n",
            "         fra       0.96      0.95      0.96      2014\n",
            "         eng       0.96      0.97      0.96      3280\n",
            "\n",
            "    accuracy                           0.96      7268\n",
            "   macro avg       0.96      0.96      0.96      7268\n",
            "weighted avg       0.96      0.96      0.96      7268\n",
            "\n",
            "Micro F1: 0.9620253164556962\n",
            "Macro F1 0.9616142202227483\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_val, y_val_pred, target_names=y_symbols))\n",
        "print('Micro F1:', f1_score(y_val, y_val_pred, average='micro'))\n",
        "print('Macro F1', f1_score(y_val, y_val_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olWbRGUV8lBv"
      },
      "source": [
        "Print the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBvYoByV8lBv",
        "outputId": "94448777-cc5c-4c31-b54d-50668061f7ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1898,   16,   60],\n",
              "       [  23, 1919,   72],\n",
              "       [  41,   64, 3175]])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ],
      "source": [
        "confusion_matrix(y_val, y_val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkZ6HUbhOLy8",
        "outputId": "c06feca3-6ba4-4477-bcea-1703aec9829f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96,)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjKXr2iP8lBv"
      },
      "source": [
        "Predict your languages with Keras. Reuse `X_test` and call the result `Y_test_pred_proba`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbmG_IrD8lBv"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "Y_test_pred_proba = model.predict(np.array(X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFGINkQM8lBw",
        "outputId": "809fe656-036d-44c6-d391-c853551920f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4291654e-01, 5.3150606e-01, 2.5577381e-02],\n",
              "       [9.9838591e-01, 1.4349347e-04, 1.4706150e-03],\n",
              "       [2.0313782e-03, 2.8379817e-04, 9.9768484e-01],\n",
              "       [9.8025954e-01, 1.9502448e-02, 2.3803693e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "Y_test_pred_proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQznMxgc8lBw"
      },
      "source": [
        "From the probabilities, extract the predicted languages and map them to strings. Call the results `pred_languages_keras`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhAIiph38lBw"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "y_test_pred = [np.argmax(row) for row in Y_test_pred_proba]\n",
        "pred_languages_keras = [idx2lang[pred] for pred in y_test_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkdliRDG8lBw",
        "outputId": "39ed1dc7-c2fc-4acb-8ced-1be60585b842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fra', 'swe', 'eng', 'swe']"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "pred_languages_keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_ouxSma8lBx"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACtRFVsL8lBx"
      },
      "source": [
        "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHjPELeS8lBx"
      },
      "outputs": [],
      "source": [
        "STIL_ID = [\"ni5324ro-s\", \"si7660da-s\"] # Write your stil ids as a list\n",
        "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
        "                                     \"/content/drive/MyDrive/Colab Notebooks/3-language_detector_keras.ipynb\") # Write the name of your notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jo30rF6yPf1M",
        "outputId": "bd621d84-40bb-46c6-ba3f-4dcb193c7f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sKZJyzw8lBx"
      },
      "source": [
        "The submission code will send your answer. It consists of the predicted languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RwegKikD8lBx",
        "outputId": "a0ae4511-83a0-4b4e-dd63-be79bc57947e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"pred_langs\": [\"fra\", \"swe\", \"eng\", \"swe\"]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "ANSWER = json.dumps({'pred_langs': pred_languages})\n",
        "ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VkxE8iT8lBx"
      },
      "source": [
        "Now the moment of truth:\n",
        "1. Save your notebook and\n",
        "2. Run the cells below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qGtevuz8lBy"
      },
      "outputs": [],
      "source": [
        "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbyaco7Y8lBy"
      },
      "outputs": [],
      "source": [
        "ASSIGNMENT = 3\n",
        "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
        "\n",
        "# Copy and compress current notebook\n",
        "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
        "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
        "        fout.write(fin.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TogKtB568lBy",
        "outputId": "1be33c53-9e6f-465a-85a5-d39ac7fbac93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'msg': None,\n",
              " 'status': 'correct',\n",
              " 'signature': '2ab7637dc4637b04eb5ab563daf2bbf0c6079687f19e3b939fde18651dc89e1b5c877c57517ff42343c615604c5d8fefcb34bc6dd2e53433678c09fc4b998b3b',\n",
              " 'submission_id': 'c0236019-ff34-4b45-9514-8bdd49705012'}"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
        "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
        "                    data={\n",
        "                        \"stil_id\": STIL_ID,\n",
        "                        \"assignment\": ASSIGNMENT,\n",
        "                        \"answer\": ANSWER,\n",
        "                        \"api_key\": API_KEY,\n",
        "                    },\n",
        "               verify=True)\n",
        "\n",
        "# from IPython.display import display, JSON\n",
        "res.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFA12mBk8lBy"
      },
      "source": [
        "## Turning in your assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4A-Bldq8lBy"
      },
      "source": [
        "Now your are done with the program. To complete this assignment, you will:\n",
        "1. Write a short individual report on your program. Do not forget to:\n",
        "   * Summarize CLD3 and outline its architecture\n",
        "   * Identify the features used by CLD3\n",
        "   * Describe your architecture and tell how it is different from CLD3\n",
        "   * Include the feature matrix you computed manually\n",
        "   * Outline the differences between sklearn and the neural network API you choose\n",
        "\n",
        "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
        "1. Write directly your text in Canvas, or\n",
        "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
        "\n",
        "The submission deadline is September 30, 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4uCkBob8lB0"
      },
      "source": [
        "## Postscript from Pierre Nugues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C22TJvK28lB0"
      },
      "source": [
        "I created this assignment from an examination I wrote in 2019 for the course on applied machine learning. I simplified it from the `README.md` on GitHub, https://github.com/google/cld3. I found the C++ code difficult to understand and I reimplemented a Keras/Tensorflow version of it from this `README`. Should you be interested, you can find it here: https://github.com/pnugues/language-detector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx5_iQ8h8lB0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BSAGNlYY8lBR",
        "Mj7hLxxI8lBU",
        "vZ7yG2hx8lBV",
        "05SkkqQc8lBV",
        "7ugzBZhD8lBX",
        "jibbJcRS8lBY",
        "S9AXW3Tx8lBZ",
        "CkzmO9rk8lBa",
        "WR8lMIVt8lBb",
        "A_SZATFi8lBc",
        "MReQWYFU8lBe",
        "Uo4ikoKj8lBe",
        "n_ouxSma8lBx",
        "uFA12mBk8lBy",
        "q4uCkBob8lB0"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}